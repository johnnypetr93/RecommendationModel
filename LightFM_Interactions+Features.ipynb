{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab74d637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janpetr/Desktop/JobHunt/_PythonProjects/DatasenticsTask/func.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books=pd.read_csv('data/Books.csv')\n",
      "/Users/janpetr/anaconda3/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from func import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from lightfm import LightFM, cross_validation\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from enum import Enum, auto\n",
    "\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc391f3",
   "metadata": {},
   "source": [
    "<h1>Obsah:</h1>\n",
    "\n",
    "<ul>\n",
    "    \n",
    "- Čtení dat, preprocessing, příprava vstupů pro model\n",
    "- Trénování modelu\n",
    "- Evaluace modelu\n",
    "- Predikce pro náhodného uživatele z existujícího datasetu\n",
    "- Zavedení nového uživatele (hodnotil knihy, které neměly hodnocení)\n",
    "- Zavedení nového uživatele (hodnotil knihy, které již byly hodnocené)\n",
    "- (Cold start problem) Zavedení nového uživatele - bez hodnocení, pouze na základě user features\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439b201",
   "metadata": {},
   "source": [
    "<h1>Funkce</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d8a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionType(Enum):\n",
    "    WORST = auto()\n",
    "    BEST = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797db398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions_filtering(dataset):\n",
    "    \"\"\"\n",
    "    Pouze první trénovací dataset. Nové interakce neočisťujeme.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definovat společné IDs s Books i Users\n",
    "    common_ids_isbn = pd.merge(ratings, books, on=\"ISBN\", how=\"inner\")[\"ISBN\"].unique()\n",
    "    common_ids_userid = pd.merge(ratings, users, on=\"User-ID\", how=\"inner\")[\"User-ID\"].unique()\n",
    "\n",
    "    # Očistit dataset o hodnoty, které nejsou v Book a Users - nutné\n",
    "    dataset = dataset[dataset[\"ISBN\"].isin(common_ids_isbn) & dataset[\"User-ID\"].isin(common_ids_userid)]\n",
    "    \n",
    "    # Pouze explicitní feedback, nikoli implicitní (viz zadání)\n",
    "    dataset = dataset[dataset[\"Book-Rating\"] > 0] # pozitivní vliv na metriky\n",
    "    \n",
    "    # Pouze knihy, které byly hodnocené xkrát a více\n",
    "    dataset = dataset.groupby(\"ISBN\").filter(lambda x: len(x)>=15)\n",
    "    \n",
    "    # Pouze uživatelé, kteří hodnotily x a více knih (cold start)\n",
    "    dataset = dataset[dataset.groupby(\"User-ID\").ISBN.transform('nunique')>=10]\n",
    "    \n",
    "    # Upravit velikost datasetu kvůli délce trénování a evaluace modelu.\n",
    "    if len(dataset) > 150000:\n",
    "        dataset = dataset.sample(150000)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def dataset_preprocessing(dataset):\n",
    "    # Ponechat hodnocení v původním stavu\n",
    "    dataset[\"OriginalRating\"] = dataset[\"Book-Rating\"]\n",
    "    \n",
    "    # Ponechat pouze hodnocení x+\n",
    "    #dataset = dataset[dataset[\"Book-Rating\"]>7]\n",
    "    \n",
    "    # !Není možné použít v kombinaci s metodou odčítání od průměru. Exponenciálně větší šance na doporučení s přibývajícím hodnocením.\n",
    "    #dataset[\"Book-Rating\"] = dataset[\"Book-Rating\"].transform(lambda x: x*x)\n",
    "    \n",
    "    # Každý má hodnotící standard nastavený jinak. Mirka Spáčilová dává nejvíce 7/10.\n",
    "    #dataset[\"Book-Rating\"] = dataset.groupby(\"User-ID\")[\"Book-Rating\"].transform(lambda x: (x - x.mean()) / x.std()) #\" \"\n",
    "    #dataset[\"Book-Rating\"] = dataset[\"Book-Rating\"].fillna(0)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def split_location(location):\n",
    "    parts = location.split(\",\")\n",
    "\n",
    "    while len(parts) < 3:\n",
    "        parts.insert(0, \"\")  \n",
    "    city = parts[-3].strip() if parts[-1] else \"\" \n",
    "    region = parts[-2].strip() if len(parts) > 1 and parts[-2] else \"\"\n",
    "    country = parts[-1].strip() if len(parts) > 2 and parts[-3] else \"\"\n",
    "    \n",
    "    return pd.Series([city, region, country], index=['city', 'region', 'country'])\n",
    "\n",
    "def input_preparation(dataframe, dataset):\n",
    "    dataset_tuple = list(zip(dataframe[\"User-ID\"], dataframe[\"ISBN\"], dataframe[\"Book-Rating\"]))\n",
    "    interactions, weights = dataset.build_interactions(i for i in dataset_tuple)\n",
    "    return interactions, weights\n",
    "\n",
    "def check_isbns(isbn_list):\n",
    "    isbn_set = set(isbn_list)\n",
    "    books_isbn_set = set(books[\"ISBN\"])\n",
    "    \n",
    "    common_isbns = isbn_set.intersection(books_isbn_set)\n",
    "    \n",
    "    invalid_isbns = [x for x in isbn_set if x not in books_isbn_set]\n",
    "    \n",
    "    print(f\"{len(common_isbns)}/{len(isbn_set)} valid ISBNs.\")\n",
    "    \n",
    "    if len(common_isbns) != len(isbn_set):\n",
    "        print(\"\")\n",
    "        print (\"Invalid ISBNs:\")\n",
    "        for isbn in invalid_isbns:\n",
    "            print(isbn)\n",
    "\n",
    "def previous_ratings(userid, noitems=None):\n",
    "    user_ratings = ratings[ratings[\"User-ID\"]==userid]\n",
    "    user_books = pd.merge(user_ratings, books, on=\"ISBN\")\n",
    "    user_books = user_books.sort_values(by=\"Book-Rating\", ascending=False)\n",
    "    \n",
    "    if noitems is not None:\n",
    "        user_books = user_books[:noitems]\n",
    "\n",
    "    print(f\"User ID: {userid}. Previous ratings (highest to lowest):\")\n",
    "\n",
    "    for _, row in user_books.iterrows():\n",
    "        print(f\"- {int((row['OriginalRating']))}*, {row['Book-Title']}, {row['Book-Author']}, {row['Year-Of-Publication']} (ISBN: {row['ISBN']})\")\n",
    "        \n",
    "def prediction(userid, where, noitems, remove_rated):\n",
    "    usercode = user_id_map.get(userid)\n",
    "    \n",
    "    _, n_items = train_interactions.shape\n",
    "    scores = pd.Series(model.predict(usercode,np.arange(n_items)))\n",
    "\n",
    "    items = pd.DataFrame(scores)\n",
    "\n",
    "    items.index = items.index.map(item_id_inverse_map)\n",
    "    items = items.reset_index(names=\"ISBN\").rename(columns={0: \"prob\"})\n",
    "\n",
    "    if remove_rated == True:\n",
    "        ratedisbn = ratings[ratings[\"User-ID\"]==userid][\"ISBN\"]\n",
    "    elif remove_rated == False:\n",
    "        ratedisbn = []\n",
    "\n",
    "    booksfinal = pd.merge(books,items,on=\"ISBN\",how=\"inner\")\n",
    "\n",
    "    if where == PredictionType.BEST:\n",
    "        booksfinal = booksfinal.sort_values(by=\"prob\", ascending=False)\n",
    "        print(f\"Predicted: best {noitems}:\")\n",
    "    elif where == PredictionType.WORST:\n",
    "        booksfinal = booksfinal.sort_values(by=\"prob\", ascending=True)\n",
    "        print(f\"Predictd: worst {noitems}:\")\n",
    "\n",
    "    for _, row in booksfinal[~booksfinal[\"ISBN\"].isin(ratedisbn)][:noitems].iterrows():\n",
    "        print(f\"- {row['Book-Title']}, {row['Book-Author']}, {row['Year-Of-Publication']} (ISBN: {row['ISBN']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbbf1c",
   "metadata": {},
   "source": [
    "<h1>Data Reading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c4abe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/1x4xl1_92cj02tdf3gqfw5qm0000gn/T/ipykernel_45989/2216795062.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books=pd.read_csv('data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"data/Ratings.csv\")\n",
    "books=pd.read_csv('data/Books.csv')\n",
    "users=pd.read_csv(\"data/Users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe73de",
   "metadata": {},
   "source": [
    "<h1>DataFrame Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ebbfa",
   "metadata": {},
   "source": [
    "<h2>Ratings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4dbf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>OriginalRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>277427</td>\n",
       "      <td>0061009059</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>277427</td>\n",
       "      <td>0316776963</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>277427</td>\n",
       "      <td>0345413903</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>277427</td>\n",
       "      <td>0380702843</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149590</th>\n",
       "      <td>276680</td>\n",
       "      <td>0688163173</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149592</th>\n",
       "      <td>276680</td>\n",
       "      <td>0743203631</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149604</th>\n",
       "      <td>276680</td>\n",
       "      <td>0743486226</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149629</th>\n",
       "      <td>276680</td>\n",
       "      <td>1573229083</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149637</th>\n",
       "      <td>276680</td>\n",
       "      <td>1931561648</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating  OriginalRating\n",
       "1456      277427  002542730X           10              10\n",
       "1474      277427  0061009059            9               9\n",
       "1522      277427  0316776963            8               8\n",
       "1543      277427  0345413903           10              10\n",
       "1564      277427  0380702843            8               8\n",
       "...          ...         ...          ...             ...\n",
       "1149590   276680  0688163173           10              10\n",
       "1149592   276680  0743203631            7               7\n",
       "1149604   276680  0743486226            6               6\n",
       "1149629   276680  1573229083            7               7\n",
       "1149637   276680  1931561648            9               9\n",
       "\n",
       "[51689 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = interactions_filtering(ratings)\n",
    "ratings = dataset_preprocessing(ratings)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6183a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users:  2158\n",
      "Unique books:  3140\n"
     ]
    }
   ],
   "source": [
    "interactions_unique_users = ratings[\"User-ID\"].unique()\n",
    "interactions_unique_isbns = ratings[\"ISBN\"].unique()\n",
    "\n",
    "print(\"Unique users: \", len(interactions_unique_users))\n",
    "print(\"Unique books: \", len(interactions_unique_isbns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddfe64",
   "metadata": {},
   "source": [
    "<h2>Users (features)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b73b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e599ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozdělení Location feature na City, Region a Country\n",
    "users[[\"City\", \"Region\", \"Country\"]] = users[\"Location\"].apply(lambda x: split_location(x))\n",
    "\n",
    "# Nahrazení NaN hodnot ve věku nejčetnější hodnotou v datasetu\n",
    "users[\"Age\"] = users[\"Age\"].fillna(users[\"Age\"].mode()[0])\n",
    "\n",
    "# Odstranění uživatelů, kteří nejsou v Ratings datasetu - kvůli dimenzionalitě\n",
    "users = users[users[\"User-ID\"].isin(set(interactions_unique_users))]\n",
    "\n",
    "# List všech features - vstup pro dataset\n",
    "unique_user_features = users[[\"Age\", \"City\", \"Region\", \"Country\"]].values.flatten().tolist()\n",
    "\n",
    "# Veškeré features spojené s User Id\n",
    "user_features_tpl = [(user_id, [age, city, region, country]) \n",
    "             for user_id, age, city, region, country \n",
    "             in zip(users[\"User-ID\"], users[\"Age\"], users[\"City\"], users[\"Region\"], users[\"Country\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08c29a",
   "metadata": {},
   "source": [
    "<h2>Books (features)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b21b12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a97853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odstranění knih, kteří nejsou v Ratings datasetu - kvůli dimenzionalitě\n",
    "books = books[books[\"ISBN\"].isin(set(interactions_unique_isbns))]\n",
    "\n",
    "# List všech features - vstup pro dataset\n",
    "unique_book_features = books[[\"Book-Author\", \"Year-Of-Publication\", \"Publisher\"]].values.flatten().tolist()\n",
    "\n",
    "# Veškeré features spojené s ISBN\n",
    "book_features_tpl = [(isbn, [author, year, publisher]) \n",
    "             for isbn, author, year, publisher \n",
    "             in zip(books[\"ISBN\"], books[\"Book-Author\"], books[\"Year-Of-Publication\"], books[\"Publisher\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47483767",
   "metadata": {},
   "source": [
    "<h1>Train/Test split (Interactions)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe4480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3bd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique user IDs\n",
    "user_ids = ratings['User-ID'].unique()\n",
    "\n",
    "# Split user IDs into train and test sets\n",
    "train_users, test_users = train_test_split(user_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the DataFrame into train and test sets based on user IDs\n",
    "train = ratings[ratings['User-ID'].isin(train_users)]\n",
    "test = ratings[ratings['User-ID'].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a75f9f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 41066 hodnocení\n",
      "Unikátní uživatelé:  1726\n",
      "Unikátní knihy:  3137\n",
      "AVG počet hodnocení na uživatele:  23.792584009269987\n",
      "AVG počet hodnocení na knihu:  13.090851131654446\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\", len(train), \"hodnocení\")\n",
    "print(\"Unikátní uživatelé: \", len(train[\"User-ID\"].unique()))\n",
    "print(\"Unikátní knihy: \", len(train[\"ISBN\"].unique()))\n",
    "print(\"AVG počet hodnocení na uživatele: \", len(train) / len(train[\"User-ID\"].unique()))\n",
    "print(\"AVG počet hodnocení na knihu: \", len(train) / len(train[\"ISBN\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c57a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 10623 hodnocení\n",
      "Unikátní uživatelé:  432\n",
      "Unikátní knihy:  2790\n",
      "AVG počet hodnocení na uživatele:  24.59027777777778\n",
      "AVG počet hodnocení na knihu:  3.80752688172043\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\", len(test), \"hodnocení\")\n",
    "print(\"Unikátní uživatelé: \", len(test[\"User-ID\"].unique()))\n",
    "print(\"Unikátní knihy: \", len(test[\"ISBN\"].unique()))\n",
    "print(\"AVG počet hodnocení na uživatele: \", len(test) / len(test[\"User-ID\"].unique()))\n",
    "print(\"AVG počet hodnocení na knihu: \", len(test) / len(test[\"ISBN\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd06f49",
   "metadata": {},
   "source": [
    "<h1>Input preparation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8986205",
   "metadata": {},
   "source": [
    "<h2>Interactions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42d4aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = Dataset()\n",
    "full_dataset.fit(users=interactions_unique_users, \n",
    "                 items=interactions_unique_isbns, \n",
    "                 user_features=unique_user_features,\n",
    "                 item_features=unique_book_features)\n",
    "\n",
    "\n",
    "user_id_map, user_features_map, item_id_map, item_features_map = full_dataset.mapping()\n",
    "\n",
    "user_id_inverse_map = {v: k for k, v in user_id_map.items()}\n",
    "item_id_inverse_map = {v: k for k, v in item_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c9571c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, train_weights = input_preparation(train, full_dataset)\n",
    "test_interactions, test_weights = input_preparation(test, full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ced27",
   "metadata": {},
   "source": [
    "<h2>Features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e282aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_matrix = full_dataset.build_user_features(user_features_tpl, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f92fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_matrix = full_dataset.build_item_features(book_features_tpl, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f82a3c3",
   "metadata": {},
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20ec7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(loss=\"warp\",\n",
    "                learning_schedule=\"adagrad\",\n",
    "                learning_rate=0.01,\n",
    "                item_alpha=0.005, # L2 regularizace\n",
    "                user_alpha=0.005,\n",
    "                no_components = 250,\n",
    "                k=10,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5154059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████| 100/100 [01:09<00:00,  1.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x2bb20db50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_interactions,\n",
    "          sample_weight=train_weights,\n",
    "          user_features=user_features_matrix,\n",
    "          item_features=item_features_matrix,\n",
    "          epochs=100, \n",
    "          num_threads=4,\n",
    "          verbose=True,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4ceec",
   "metadata": {},
   "source": [
    "<h1>Model Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "827dce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.9927167892456055\n",
      "Test AUC: 0.6455078721046448\n"
     ]
    }
   ],
   "source": [
    "train_auc = auc_score(model,\n",
    "                      train_interactions,\n",
    "                      user_features=user_features_matrix,\n",
    "                      item_features=item_features_matrix,\n",
    "                     ).mean()\n",
    "\n",
    "test_auc = auc_score(model,\n",
    "                     test_interactions,\n",
    "                     train_interactions=train_interactions,\n",
    "                     user_features=user_features_matrix,\n",
    "                     item_features=item_features_matrix,\n",
    "                    ).mean()\n",
    "\n",
    "print(f\"Train AUC: {train_auc}\")\n",
    "print(f\"Test AUC: {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59d88f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.5327925682067871\n",
      "Test Precision: 0.05486111342906952\n"
     ]
    }
   ],
   "source": [
    "train_precision = precision_at_k(model,\n",
    "                                 train_interactions,\n",
    "                                 user_features=user_features_matrix,\n",
    "                                 item_features=item_features_matrix,\n",
    "                                 k=10,\n",
    "                                ).mean()\n",
    "\n",
    "test_precision = precision_at_k(model,\n",
    "                                test_interactions,\n",
    "                                train_interactions=train_interactions,\n",
    "                                user_features=user_features_matrix,\n",
    "                                item_features=item_features_matrix,\n",
    "                                k=10,\n",
    "                                ).mean()\n",
    "\n",
    "print(f\"Train Precision: {train_precision}\")\n",
    "print(f\"Test Precision: {test_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52fbf4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.29586290165683843\n",
      "Test Recall: 0.02485984105859187\n"
     ]
    }
   ],
   "source": [
    "train_recall = recall_at_k(model,\n",
    "                           train_interactions,\n",
    "                           user_features=user_features_matrix,\n",
    "                           item_features=item_features_matrix,\n",
    "                           k=10,\n",
    "                          ).mean()\n",
    "\n",
    "test_recall = recall_at_k(model,\n",
    "                          test_interactions,\n",
    "                          train_interactions=train_interactions,\n",
    "                          user_features=user_features_matrix,\n",
    "                          item_features=item_features_matrix,\n",
    "                          k=10,\n",
    "                         ).mean()\n",
    "\n",
    "print(f\"Train Recall: {train_recall}\")\n",
    "print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66868e",
   "metadata": {},
   "source": [
    "<h1>Single user Prediction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ef5fc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/1x4xl1_92cj02tdf3gqfw5qm0000gn/T/ipykernel_45989/3419819421.py:1: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  userid = int(ratings.sample(1)[\"User-ID\"]) # random user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167494"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid = int(ratings.sample(1)[\"User-ID\"]) # random user\n",
    "userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e861e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 167494. Previous ratings (highest to lowest):\n",
      "- 8*, The Tommyknockers, Stephen King, 1994 (ISBN: 0451156609)\n",
      "- 8*, The Color of Water: A Black Man's Tribute to His White Mother, James McBride, 1997 (ISBN: 1573225789)\n",
      "- 7*, Red Dragon, Thomas Harris, 2000 (ISBN: 0440206154)\n",
      "- 7*, The Witch of Blackbird Pond (Laurel Leaf Books), ELIZABETH GEORGE SPEARE, 1978 (ISBN: 0440995779)\n",
      "- 7*, Seinlanguage, Jerry Seinfeld, 1995 (ISBN: 0553569155)\n",
      "- 7*, All the Pretty Horses (The Border Trilogy, Vol 1), CORMAC MCCARTHY, 1993 (ISBN: 0679744398)\n",
      "- 7*, What Dreams May Come : A Novel, Richard Matheson, 1998 (ISBN: 0812570944)\n",
      "- 6*, The Accidental Tourist, Anne Tyler, 1994 (ISBN: 0425092917)\n",
      "- 5*, FORREST GUMP (Movie Tie in), Winston Groom, 1994 (ISBN: 0671894455)\n",
      "- 5*, All I Really Need to Know, ROBERT FULGHUM, 1989 (ISBN: 080410526X)\n"
     ]
    }
   ],
   "source": [
    "previous_ratings(userid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34307ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: best 10:\n",
      "- The Lovely Bones: A Novel, Alice Sebold, 2002 (ISBN: 0316666343)\n",
      "- The Da Vinci Code, Dan Brown, 2003 (ISBN: 0385504209)\n",
      "- Interview with the Vampire, Anne Rice, 1993 (ISBN: 0345337662)\n",
      "- Where the Heart Is (Oprah's Book Club (Paperback)), Billie Letts, 1998 (ISBN: 0446672211)\n",
      "- Harry Potter and the Order of the Phoenix (Book 5), J. K. Rowling, 2003 (ISBN: 043935806X)\n",
      "- Girl with a Pearl Earring, Tracy Chevalier, 2001 (ISBN: 0452282152)\n",
      "- Good in Bed, Jennifer Weiner, 2002 (ISBN: 0743418174)\n",
      "- 1st to Die: A Novel, James Patterson, 2002 (ISBN: 0446610038)\n",
      "- Face the Fire (Three Sisters Island Trilogy), Nora Roberts, 2002 (ISBN: 051513287X)\n",
      "- SHIPPING NEWS, Annie Proulx, 1994 (ISBN: 0671510053)\n"
     ]
    }
   ],
   "source": [
    "prediction(userid, PredictionType.BEST, 10, remove_rated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbdf68",
   "metadata": {},
   "source": [
    "<h1>New user: books unrated before</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6cd1f",
   "metadata": {},
   "source": [
    "<h2>Update datasetu a modelu</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf05a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "New User Testing\n",
    "user_id = 123456\n",
    "\n",
    "Sci-Fi Fantasy fan\n",
    "Crime not fan\n",
    "\n",
    "375704027 -> 9 (Murakami)\n",
    "385177259 -> 10 (Asimov)\n",
    "345309014 -> 10 (Asimov)\n",
    "60929871 -> 8 (Brave New World, Huxley)\n",
    "553106635 -> 10 (Game of Thrones)\n",
    "3548245978 -> 1 (Nesbo)\n",
    "3548255442 -> 2 (Nesbo)\n",
    "877959943 -> 1 (McBain)\n",
    "877959870 -> 4 (McBain)\n",
    "446517380 -> 3 (McBain)\n",
    "553256785 -> 2 (A. Christie)\n",
    "671555235 -> 3 (A. Christie)\n",
    "\"\"\"\n",
    "\n",
    "ratings_new_userid = 123456\n",
    "ratings_new_isbn = [\"0375704027\", \n",
    "                    \"0385177259\", \n",
    "                    \"0345309014\", \n",
    "                    \"0060929871\", \n",
    "                    \"0553106635\", \n",
    "                    \"3548245978\", \n",
    "                    \"3548255442\", \n",
    "                    \"0877959943\", \n",
    "                    \"0877959870\", \n",
    "                    \"0446517380\", \n",
    "                    \"0553256785\", \n",
    "                    \"0671555235\"]\n",
    "ratings_new_rating = [9, 10, 10, 8, 10, 1, 2, 1, 4, 3, 2, 3]\n",
    "ratings_new = pd.DataFrame({\n",
    "    \"User-ID\": ratings_new_userid,\n",
    "    \"ISBN\": ratings_new_isbn,\n",
    "    \"Book-Rating\": ratings_new_rating\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af840f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/12 valid ISBNs.\n",
      "\n",
      "Invalid ISBNs:\n",
      "0385177259\n",
      "3548245978\n",
      "0345309014\n",
      "0446517380\n",
      "0671555235\n",
      "0877959870\n",
      "0553256785\n",
      "3548255442\n",
      "0877959943\n",
      "0553106635\n"
     ]
    }
   ],
   "source": [
    "check_isbns(ratings_new_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e443939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing nových dat\n",
    "ratings_new = dataset_preprocessing(ratings_new)\n",
    "\n",
    "# Spojení v celým Ratings datasetem\n",
    "ratings = pd.concat([ratings, ratings_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c56ee057",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.fit_partial(users=ratings_new[\"User-ID\"].unique(), \n",
    "                         items=ratings_new[\"ISBN\"].unique())\n",
    "\n",
    "user_id_map, user_feature_map, item_id_map, item_feature_map = full_dataset.mapping()\n",
    "\n",
    "user_id_inverse_map = {v: k for k, v in user_id_map.items()}\n",
    "item_id_inverse_map = {v: k for k, v in item_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "973c6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interactions, new_weights = input_preparation(ratings_new, full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc38a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████| 1/1 [00:00<00:00, 357.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x2bb20db50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Partial for Model (model.fit_partial) nefunguje pro nové uživatele - dimenzionalita nesedí\n",
    "\n",
    "model.fit(new_interactions,\n",
    "          sample_weight=new_weights,\n",
    "          #user_features=user_features_matrix,\n",
    "          #item_features=item_features_matrix,\n",
    "          num_threads=4,\n",
    "          verbose=True,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af5114",
   "metadata": {},
   "source": [
    "<h2>Predikce</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52ac49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 123456. Previous ratings (highest to lowest):\n",
      "- 9*, Norwegian Wood (Vintage International Original), Haruki Murakami, 2000 (ISBN: 0375704027)\n",
      "- 8*, Brave New World, Aldous Huxley, 1998 (ISBN: 0060929871)\n",
      "\n",
      "Predicted: best 10:\n",
      "- Norwegian Wood (Vintage International Original), Haruki Murakami, 2000 (ISBN: 0375704027)\n",
      "- Brave New World, Aldous Huxley, 1998 (ISBN: 0060929871)\n",
      "- Relic, Douglas Preston, 2003 (ISBN: 0812543262)\n",
      "- Back When We Were Grownups : A Novel (Ballantine Reader's Circle), ANNE TYLER, 2002 (ISBN: 0345446860)\n",
      "- Loose Screws (Red Dress Ink (Paperback)), Karen Templeton, 2002 (ISBN: 0373250193)\n",
      "- Blood Shot (V.I. Warshawski Novels (Paperback)), Sara Paretsky, 1989 (ISBN: 0440204208)\n",
      "- Tunnel Vision (V.I. Warshawski Novels (Paperback)), Sara Paretsky, 1995 (ISBN: 0440217520)\n",
      "- Love You Forever, Robert N. Munsch, 1986 (ISBN: 0920668372)\n",
      "- The Notebook, Nicholas Sparks, 1998 (ISBN: 0446605239)\n",
      "- Still Pumped From Using The Mouse, Scott Adams, 1996 (ISBN: 0836210263)\n"
     ]
    }
   ],
   "source": [
    "# Problém je, že knihy v novém datasetu nebyly hodnoceny vícekrát, takže predikce pokulhává.\n",
    "\n",
    "user_id = 123456\n",
    "no_items = 10\n",
    "\n",
    "previous_ratings(user_id, no_items) \n",
    "print(\"\")\n",
    "prediction(user_id, PredictionType.BEST, no_items, remove_rated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a59b88",
   "metadata": {},
   "source": [
    "<h1>New user: book rated before</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62c1684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fan of Sci-fi\n",
    "Not a Fan of Classics\n",
    "\n",
    "60809833 -> Brave New World, Huxley\n",
    "60914653 -> The Unbearable Lightness of Being, Kundera\n",
    "60934913 -> Kitchen Confidential: Adventures in the Culinary Underbelly, Anthony Bourdain\n",
    "61020710 -> The Color of Magic, Terry Pratchett\n",
    "64471047 -> The Lion, the Witch, and the Wardrobe (The Chronicles of Narnia, Book 2), C. S. Lewis\n",
    "64471063 -> The Horse and His Boy, C. S. Lewis\n",
    "64471101 -> The Magician's Nephew (rack) (Narnia), C. S. Lewis\n",
    "64407667 -> The Bad Beginning (A Series of Unfortunate Events, Book 1), Lemony Snicket\n",
    "64407675 -> The Reptile Room (A Series of Unfortunate Events, Book 2), Lemony Snicket\n",
    "64407683 -> The Wide Window (A Series of Unfortunate Events, Book 3), Lemony Snicket\n",
    "140042393 -> The Grapes of Wrath, John Steinbeck\n",
    "140042520 -> Dharma Bums, Jack Kerouac\n",
    "140042598 -> On the Road, Jack Kerouac\n",
    "140053204 -> Travels With Charley: In Search of America, John Steinbeck\n",
    "345303067 -> 2010: Odyssey Two, Arthur C. Clarke\n",
    "345339703 -> The Fellowship of the Ring (The Lord of the Rings, Part 1), J.R.R. TOLKIEN\n",
    "345339711 -> The Two Towers (The Lord of the Rings, Part 2), J.R.R. TOLKIEN\n",
    "345389964 -> A Son of the Circus, John Irving\n",
    "\"\"\"\n",
    "\n",
    "ratings_new_userid = 123457\n",
    "ratings_new_isbn = ['0060809833', \n",
    "                    '0060914653', \n",
    "                    '0060934913', \n",
    "                    '0061020710', \n",
    "                    '0064471047', \n",
    "                    '0064471063', \n",
    "                    '0064471101', \n",
    "                    '0064407667', \n",
    "                    '0064407675', \n",
    "                    '0064407683', \n",
    "                    '0140042393', \n",
    "                    '0140042520', \n",
    "                    '0140042598', \n",
    "                    '0140053204', \n",
    "                    '0345303067', \n",
    "                    '0345339703', \n",
    "                    '0345339711', \n",
    "                    '0345389964']\n",
    "ratings_new_rating = [9,2,1,8,9,10,8, 7, 7, 8, 0, 3, 1, 2, 8, 9, 10, 4]\n",
    "ratings_new = pd.DataFrame({\n",
    "    \"User-ID\": ratings_new_userid,\n",
    "    \"ISBN\": ratings_new_isbn,\n",
    "    \"Book-Rating\": ratings_new_rating\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0041716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50609fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 valid ISBNs.\n"
     ]
    }
   ],
   "source": [
    "check_isbns(ratings_new_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14dcaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing nových dat\n",
    "ratings_new = dataset_preprocessing(ratings_new)\n",
    "\n",
    "# Spojení v celým Ratings datasetem\n",
    "ratings = pd.concat([ratings, ratings_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98483d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.fit_partial(users=ratings_new[\"User-ID\"].unique(), \n",
    "                         items=ratings_new[\"ISBN\"].unique())\n",
    "\n",
    "user_id_map, user_feature_map, item_id_map, item_feature_map = full_dataset.mapping()\n",
    "\n",
    "user_id_inverse_map = {v: k for k, v in user_id_map.items()}\n",
    "item_id_inverse_map = {v: k for k, v in item_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "164205a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interactions, new_weights = input_preparation(ratings_new, full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c7a7204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████| 1/1 [00:00<00:00, 479.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x2bb20db50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Partial for Model (model.fit_partial) nefunguje pro nové uživatele - dimenzionalita neodpovídá\n",
    "\n",
    "model.fit(new_interactions,\n",
    "          sample_weight=new_weights,\n",
    "          num_threads=4,\n",
    "          verbose=True,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d293047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 123457. Previous ratings (highest to lowest):\n",
      "- 10*, The Two Towers (The Lord of the Rings, Part 2), J.R.R. TOLKIEN, 1986 (ISBN: 0345339711)\n",
      "- 10*, The Horse and His Boy, C. S. Lewis, 1994 (ISBN: 0064471063)\n",
      "- 9*, Brave New World, Aldous Huxley, 1989 (ISBN: 0060809833)\n",
      "- 9*, The Fellowship of the Ring (The Lord of the Rings, Part 1), J.R.R. TOLKIEN, 1986 (ISBN: 0345339703)\n",
      "- 9*, The Lion, the Witch, and the Wardrobe (The Chronicles of Narnia, Book 2), C. S. Lewis, 1994 (ISBN: 0064471047)\n",
      "- 8*, 2010: Odyssey Two, Arthur C. Clarke, 1984 (ISBN: 0345303067)\n",
      "- 8*, The Wide Window (A Series of Unfortunate Events, Book 3), Lemony Snicket, 2000 (ISBN: 0064407683)\n",
      "- 8*, The Magician's Nephew (rack) (Narnia), C. S. Lewis, 2002 (ISBN: 0064471101)\n",
      "- 8*, The Color of Magic, Terry Pratchett, 2000 (ISBN: 0061020710)\n",
      "- 7*, The Bad Beginning (A Series of Unfortunate Events, Book 1), Lemony Snicket, 1999 (ISBN: 0064407667)\n",
      "\n",
      "Predicted: best 10:\n",
      "- Different Seasons (Signet), Stephen King, 2004 (ISBN: 0451167538)\n",
      "- Schindler's List, Thomas Keneally, 1993 (ISBN: 0671880314)\n",
      "- Cujo, Stephen King, 2004 (ISBN: 0451161351)\n",
      "- The List, Steven Paul Martini, 1997 (ISBN: 0515121495)\n",
      "- Tishomingo Blues, Elmore Leonard, 2002 (ISBN: 0060083948)\n",
      "- The Pearl, John Steinbeck, 2000 (ISBN: 014017737X)\n",
      "- Little House on the Prairie, Laura Ingalls Wilder, 1953 (ISBN: 0064400026)\n",
      "- The English Patient, Michael Ondaatje, 1996 (ISBN: 0679745203)\n",
      "- Getting Over Jack Wagner, Elise Juska, 2003 (ISBN: 0743464672)\n",
      "- A Painted House, JOHN GRISHAM, 2001 (ISBN: 038550120X)\n"
     ]
    }
   ],
   "source": [
    "user_id = 123457\n",
    "no_items = 10\n",
    "\n",
    "previous_ratings(user_id, no_items) \n",
    "print(\"\")\n",
    "prediction(user_id, PredictionType.BEST, no_items, remove_rated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba73fa3",
   "metadata": {},
   "source": [
    "<h1>New user: no ratings before (cold start)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28631ab7",
   "metadata": {},
   "source": [
    "new_userid = 123458"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602b5e6",
   "metadata": {},
   "source": [
    "features = [24.0, 'arden hills', 'minnesota', 'usa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed72bb",
   "metadata": {},
   "source": [
    "full_dataset.fit_partial(users=np.array([new_userid]), \n",
    "                         user_features=features,\n",
    "                        )\n",
    "\n",
    "user_id_map, user_feature_map, item_id_map, item_feature_map = full_dataset.mapping()\n",
    "\n",
    "user_id_inverse_map = {v: k for k, v in user_id_map.items()}\n",
    "item_id_inverse_map = {v: k for k, v in item_id_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aabc6d0",
   "metadata": {},
   "source": [
    "#features\n",
    "user_tuple = (new_userid, [24.0, 'arden hills', 'minnesota', 'usa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99a8ba",
   "metadata": {},
   "source": [
    "#model.fit()\n",
    "\n",
    "model.fit(train_interactions,\n",
    "          #sample_weight=train_weights,\n",
    "          user_features=user_features_matrix,\n",
    "          #item_features=item_features_matrix,\n",
    "          #epochs=100, \n",
    "          #num_threads=4,\n",
    "          #verbose=True,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26dcef",
   "metadata": {},
   "source": [
    "<h1>Model save</h1>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f823a4e0",
   "metadata": {},
   "source": [
    "with open('lightfm_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f10e68b2",
   "metadata": {},
   "source": [
    "with open('lightfm_dataset.pkl', 'wb') as dataset_file:\n",
    "    pickle.dump(full_dataset, dataset_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
